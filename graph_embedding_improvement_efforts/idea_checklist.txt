[ Ideas to try:]

-----------------------------------------------------------------------------------------------------------------------------------
[Priority-1] TRY: Prof Guanhua said to consider “concatenating” the temporal-Ngram with graph-embedding? 
                  Graph-embedding serving as additional info.  
                  Then, in this case, baseline, should be the corresponding temporal-Ngram
   — “could” write a script : /data/d1/jgwak1/tabby/graph_embedding_improvement_JY_git/graph_embedding_improvement/concat_ngram_and_graph_embedding.py
   
         which integrates the following the “n-gram” part with “graph-embedding” part, referring to:
         -- /data/d1/jgwak1/tabby/graph_embedding_improvement_JY_git/analyze_at_model_explainer/analyze_RF_with_explainer.py
         -- /data/d1/jgwak1/tabby/graph_embedding_improvement_JY_git/N_gram_hyperparameter_tuning/n_gram_hypeparam_tuning.py

-----------------------------------------------------------------------------------------------------------------------------------
[Priority-2] Weighted-sum
   - Give lower weights on artifactual threads (~ give higher weights to more important threads )
   
   --> So what is the logic behind process starting threads?
   
   --> If a process runs a particular application, is there a straightforward way to distinguish threads that correspond to the actual activity of that application and threads that are more for background activities ?
      ^-- When looked directly into the Threadstart event ETW log-entries, and didn't see any interesting pattern.

   --> Analyze : /data/d1/jgwak1/tabby/graph_embedding_improvement_JY_git/graph_embedding_improvement_efforts/Trial_2__Weighted_Thread_Sum_Aggr/GROUPING_RESULTS
      ^-- Priti could help on this analysis task  


      
    # X does not work for json prettify --> For each (pid, tid) make list of dict-strings into 1 string delimited by "\n" so that more readable
    
    # TODO with lesser priority : [ JY @ 2023-12-28: Could write out to a txt file for more readability. ]


-----------------------------------------------------------------------------------------------------------------------------------

[Priority-3] Incorporate n-hop information flow with directed graph, similar to the neighborhood aggregation in GNN.
   
   -->  Refer to the neighborhood aggregation code of, say, 'pytorch GIN-conv layer' 

   ---> Check how the node embeddings get generalized for basic neighborhood-aggregation(message-passing)?

    # TO RESEARCH: How does the conventional GNN deal with duplicate nodes being used in message passing when the graph is a multi-graph?
    #              e.g. In multi-graph setting, node X can have multiple incoming edges from the node Y.
    #                   Then, node Y will send multiple messages to node X, 
    #                   where each message may vary by 'information from edge' but be exactly same by 'information from node',
    #                   since the latter is all based on node-feature of node Y.

    #          ---> Seems like what I've done in singal-amplification is the conventional approach
    #               (i.e., don't repeat for node-message; combine edge-feature, share common node-feature once, put it together)


   TODO: /Trial_3__Standard_Message_Passing/standard_message_passing__graph_embedding.py" seems to work.
         Do alittle sanity-checking and start tuning.

-----------------------------------------------------------------------------------------------------------------------------------
[Priority-4] Do alittle more analysis on "Investigating the reason using SHAP explainer" to see if can get clue?
    
    --> Instead of writing a script that also prints "feature value with feature shap",
        for mispredicted samples, could compare the waterfall plots of with and without graph-embedding 
        to see how their top features (w.r.t feature shap) and corresponding feature values changed

    --> Question to ponder: Why does relying solely on the distribution of events as a feature (i.e. flattened-graph features) 
                            result in decent performance? 
                            (Are the train/test samples substantially similar, leading to such result?)

    --> Understanding the data ( do this in parallel )


    --> distribution signal (sum pool 했을때 vector dist, mean/max pool 했을때 vector dist ; distribution histogram?)
                            ( data sample 별로 비교 (train/test) )

     TODO: "/analyze_at_model_explainer/explanation_comparisons.py" KIND OF WORKING BUT NEEDS DEBUGGING

     *
     Flattened vs. Max 비교해봐
     그리고 Predict-proba 높은 benign 과 malware sample들 위주 -- distribution 위주


-----------------------------------------------------------------------------------------------------------------------------------
[Priority-5] Incorporate "Local N-gram (temporal information local to pair of nodes)" to graph-embedding (i.e. 'N>1'gram between thread node and f/r/n/p node)
   -- This definitely will involve alot of work + considerations 
   -- May not be very scalable ; Prof Stoller once said to use explainer to figure out which n-gram features are less important
   -- fit_transform for all edges in training data , in parallel? , then aggregate , and transform? 
      (this will need some good amount of effort, LESS importance ** )

   ^-- Current blueprint for implementation (2024-1-1) -- as scalable as possible   
       
       1. get simple graph subgraphs (multiple events on edge) 
          --- TODO--> /data/d1/jgwak1/tabby/STREAMLINED_DATA_GENERATION_SimpleGraph_silketw_version (TODO)
                      In 'firststep' file, use "get_graph" instead of "get_multigraph",
                      Don't use "Edgedirection" file that is tailored for "multigraph" ; use the one comptabile with "simplegraph"
                      Check secondstep and etc.

                      Simple graph setting 에서 event 와 timestamp 간 1 to 1 mapping 있었었나? simple graph 의 second step 확인
                      만약 1 to 1 mapping이 없었다면 그냥 multigraph 에서 하는 방법도? ** <-- 고려 


       2. for each edge, get strings that correspond to events sorted in timestamp order (getting strings b/c compatiblity with countvectorizer)
                         so for each graph, the number of strings we get is equivalent to number of edges
       3. fit the countvectorizer with strings from all graphs based on specified N.
       4. preprocessed graph can result in grpahs with edges with ordered-event-strings.
       5. use the fitted countvectorizer to perform local-N-gram standard message passing.


-----------------------------------------------------------------------------------------------------------------------------------

[ Priti is also running the "Signal-Amplification suggested approach suggested by Prof Guanhua way back" ]

-----------------------------------------------------------------------------------------------------------------------------------

< Think and add more >

GRNN?

Are the signals (from our train/test data to acheive 85%+ exist at first place?)


If we conceptualize the information that we can get by manipulating the graph:
- Global-Temporal (flattened graph N>1 gram)
- Local-Temporal (N>1 gram between events in pairs of nodes)
- Spatial Information (~Graph-embedding)
Are there more?


Dissect all procedures , revisit and question all assumptions that we made
- e.g. How are we so sure that graph-structure will help for classification?
-      Is our


Emma -- will manage tuning during the winter

Lalji 